{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff6089a1cbc5486491bc28dfdf0842c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36c790e253404e57ab318d10f1da72dc",
              "IPY_MODEL_f8c3b5e51d75412495c13bbae53eaba6",
              "IPY_MODEL_a3264d5ecd9a40cea924a54894e3993b"
            ],
            "layout": "IPY_MODEL_0925fcbec6f0439ea07f2f825b142b4d"
          }
        },
        "36c790e253404e57ab318d10f1da72dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c78c04788dd4e0bbc3adb836aa2b507",
            "placeholder": "​",
            "style": "IPY_MODEL_143548f246b94f65bf5112a8a31c71bf",
            "value": "Generating train split: "
          }
        },
        "f8c3b5e51d75412495c13bbae53eaba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7cc08475e5048e3ab656ee1aa8e8440",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76ef52b0a5334cdd93ce494dd5284367",
            "value": 1
          }
        },
        "a3264d5ecd9a40cea924a54894e3993b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_707cc9f168e848f69c5e20beb6d5ac30",
            "placeholder": "​",
            "style": "IPY_MODEL_a43b714ffe4e4c1a93b3736f122d7af0",
            "value": " 4/0 [00:00&lt;00:00, 28.15 examples/s]"
          }
        },
        "0925fcbec6f0439ea07f2f825b142b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c78c04788dd4e0bbc3adb836aa2b507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "143548f246b94f65bf5112a8a31c71bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7cc08475e5048e3ab656ee1aa8e8440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "76ef52b0a5334cdd93ce494dd5284367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "707cc9f168e848f69c5e20beb6d5ac30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43b714ffe4e4c1a93b3736f122d7af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "114ff34dc0574fa4b68cec2720c174b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f70ead906c0d449d88fb32134dce4878",
              "IPY_MODEL_a85ef2bef2e54899bc3a52f560674d30",
              "IPY_MODEL_c03ce78d31e94034b2f849a12ecf7128"
            ],
            "layout": "IPY_MODEL_3e41c26223124bbea716420dc894faa7"
          }
        },
        "f70ead906c0d449d88fb32134dce4878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_257833c710a84ffc9842ef45c8970ffa",
            "placeholder": "​",
            "style": "IPY_MODEL_104ad1ea624849d2b906c34ee19edb72",
            "value": "100%"
          }
        },
        "a85ef2bef2e54899bc3a52f560674d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e6f26203bcb4d03ad13772550bfc171",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ad5c23abcb8469c95e1c927ac63bce7",
            "value": 1
          }
        },
        "c03ce78d31e94034b2f849a12ecf7128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c06055521f1b42b39ca64d2a7f92536e",
            "placeholder": "​",
            "style": "IPY_MODEL_e86e0ae28cc64c4d812bd8b541490ecf",
            "value": " 1/1 [00:00&lt;00:00,  3.37it/s]"
          }
        },
        "3e41c26223124bbea716420dc894faa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "257833c710a84ffc9842ef45c8970ffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "104ad1ea624849d2b906c34ee19edb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e6f26203bcb4d03ad13772550bfc171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad5c23abcb8469c95e1c927ac63bce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c06055521f1b42b39ca64d2a7f92536e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e86e0ae28cc64c4d812bd8b541490ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Prerequisites"
      ],
      "metadata": {
        "id": "QzFzH9u5lOTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \\\n",
        "    langchain==0.3.23 \\\n",
        "    langchain-community==0.3.21 \\\n",
        "    langchain-pinecone==0.2.5 \\\n",
        "    langchain-openai==0.3.12 \\\n",
        "    datasets==3.5.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ktAv0pklNm5",
        "outputId": "633c5bf3-2fd2-4922-c298-6a3fe96dab21"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: pinecone 6.0.2 does not provide the extra 'async'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.2/221.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7JxmGUoln6D",
        "outputId": "ad6da0ef-ffda-4400-e82c-fdd231bf7faf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.3.76)\n",
            "Collecting groq<1,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.32.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (25.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.11.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.32.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.5.0)\n",
            "Downloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
            "Downloading groq-0.32.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.32.0 langchain-groq-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "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"
      ],
      "metadata": {
        "id": "1uoDAktvnJb9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NL55N3I9WFc9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NO RAG"
      ],
      "metadata": {
        "id": "GZ6RmCA99vBZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l13YDnz0g47o",
        "outputId": "33fb6750-081e-45bf-c4cf-2ff7619fd62f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\") or getpass(\n",
        "    \"Enter your OpenAI API key: \"\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize Groq chat model\n",
        "chat = ChatGroq(\n",
        "    model_name=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0.7,\n",
        "    api_key=os.environ[\"GROQ_API_KEY\"]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial conversation\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
        "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
        "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
        "]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CVdixdf9maF1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get AI response\n",
        "res = chat(messages)\n",
        "print(res.content)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WFB5PZfo_g5",
        "outputId": "f92bc1e2-1b97-4065-8242-3f85e9e28a19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3419115045.py:2: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  res = chat(messages)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "String theory is a complex and fascinating topic in physics. I'll try to break it down in a way that's easy to understand.\n",
            "\n",
            "**What is string theory?**\n",
            "\n",
            "String theory proposes that the fundamental building blocks of our universe are not particles, but tiny, vibrating strings. These strings are too small to be seen, but they're thought to be the source of everything around us, from atoms to galaxies.\n",
            "\n",
            "**The problem with particles**\n",
            "\n",
            "In the early 20th century, physicists discovered that particles like electrons and photons have both wave-like and particle-like properties. This led to the development of quantum mechanics, which describes the behavior of particles at the atomic and subatomic level.\n",
            "\n",
            "However, as physicists delved deeper into the nature of particles, they encountered a problem. The equations that described particle behavior, known as quantum field theory, were inconsistent with Einstein's theory of general relativity, which describes gravity.\n",
            "\n",
            "**Enter strings**\n",
            "\n",
            "String theory attempts to resolve this inconsistency by postulating that particles are not point-like objects, but tiny, vibrating strings. These strings can vibrate at different frequencies, giving rise to the various particles we observe in the universe.\n",
            "\n",
            "Imagine a violin string, which can produce different notes when plucked at different frequencies. Similarly, the vibrating strings in string theory can produce different particles, such as electrons, photons, and quarks, depending on their vibrational modes.\n",
            "\n",
            "**Extra dimensions**\n",
            "\n",
            "Here's where things get really interesting. String theory requires the existence of extra dimensions beyond the three spatial dimensions (length, width, and depth) and one time dimension that we're familiar with.\n",
            "\n",
            "These extra dimensions are \"compactified\" or \"curled up\" so tightly that we can't directly observe them. Think of a long, thin straw, where the extra dimensions are wrapped up inside the straw, making them invisible to us.\n",
            "\n",
            "**Types of string theory**\n",
            "\n",
            "There are several variants of string theory, including:\n",
            "\n",
            "1. **Type I string theory**: This version includes both open and closed strings, which can vibrate and give rise to different particles.\n",
            "2. **Type II string theory**: This version includes supersymmetry, which proposes the existence of particles with identical properties to known particles, but with different spin values.\n",
            "3. **Heterotic string theory**: This version combines elements of type I and type II string theories.\n",
            "4. **M-theory**: This is a more recent development, which attempts to unify all the different string theories into a single framework.\n",
            "\n",
            "**Challenges and criticisms**\n",
            "\n",
            "While string theory is an active area of research, it's not without its challenges and criticisms. Some of the concerns include:\n",
            "\n",
            "1. **Lack of experimental evidence**: Despite decades of research, there's still no direct experimental evidence to support string theory.\n",
            "2. **Mathematical complexity**: String theory requires advanced mathematical tools, which can make it difficult to understand and work with.\n",
            "3. **Multiverse problem**: String theory predicts the existence of a vast \"multiverse,\" where our universe is just one of many bubbles in a vast cosmic sea. This raises questions about the testability and falsifiability of the theory.\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "String theory is a mind-bending, complex, and fascinating topic that attempts to unify our understanding of the universe. While it's still a developing area of research, it has the potential to revolutionize our understanding of space, time, and matter.\n",
            "\n",
            "I hope this brief introduction has piqued your interest in string theory! Do you have any specific questions or topics you'd like to explore further?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add latest AI response to messages\n",
        "messages.append(res)\n",
        "\n",
        "# New prompt\n",
        "prompt = HumanMessage(content=\"Why do physicists believe it can produce a 'unified theory'?\")\n",
        "messages.append(prompt)\n",
        "\n",
        "# Get AI response\n",
        "res = chat(messages)\n",
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vq5OwU0pCl8",
        "outputId": "893193f9-4fcd-4692-d9a3-aeba017af3d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physicists believe that string theory has the potential to produce a unified theory, also known as a \"theory of everything\" (ToE), for several reasons:\n",
            "\n",
            "1. **Unification of forces**: String theory attempts to unify the fundamental forces of nature, including:\n",
            "\t* Gravity (described by general relativity)\n",
            "\t* Electromagnetism (described by quantum electrodynamics)\n",
            "\t* Strong nuclear force (described by quantum chromodynamics)\n",
            "\t* Weak nuclear force (described by the electroweak theory)\n",
            "\t* String theory proposes that these forces are different vibrational modes of the same underlying strings.\n",
            "2. **Consistent with quantum mechanics and general relativity**: String theory is an attempt to reconcile the principles of quantum mechanics and general relativity, which are known to be incompatible within the framework of classical physics. By postulating that particles are vibrating strings, string theory provides a framework for merging these two theories.\n",
            "3. **Renormalizability**: String theory is a renormalizable theory, meaning that it can be formulated in a way that eliminates infinite self-energies and provides a consistent, finite description of physical phenomena. This is a crucial property for a theory that aims to describe the behavior of particles at very small distances and high energies.\n",
            "4. **Predicts the existence of gravitons**: String theory predicts the existence of gravitons, which are hypothetical particles thought to mediate the force of gravity. The existence of gravitons is a key feature of any theory that attempts to unify gravity with the other fundamental forces.\n",
            "5. **Provides a framework for understanding black holes**: String theory has been successful in providing a framework for understanding the behavior of black holes, including the calculation of black hole entropy and the resolution of the black hole information paradox.\n",
            "6. **Mathematical consistency**: String theory is based on a set of mathematical equations, known as the string equations, which are consistent with the principles of quantum mechanics and general relativity. The mathematical structure of string theory is rich and beautiful, with many interesting and unexpected features.\n",
            "7. **Potential to explain the hierarchy problem**: String theory may provide a solution to the hierarchy problem, which is the question of why the gravitational force is so much weaker than the other fundamental forces. String theory proposes that the gravitational force is weaker because it is a residual force that arises from the vibrations of strings in a higher-dimensional space.\n",
            "\n",
            "While string theory is still a developing area of research, many physicists believe that it has the potential to provide a unified theory that can explain all the fundamental phenomena in the universe, from the smallest subatomic particles to the vast expanse of the cosmos.\n",
            "\n",
            "However, it's essential to note that string theory is still a highly speculative and incomplete theory, and many challenges and open questions remain. Some of the criticisms of string theory include:\n",
            "\n",
            "* **Lack of experimental evidence**: Despite decades of research, there is still no direct experimental evidence to support string theory.\n",
            "* **Mathematical complexity**: String theory requires advanced mathematical tools, which can make it difficult to understand and work with.\n",
            "* **Multiverse problem**: String theory predicts the existence of a vast \"multiverse,\" which raises questions about the testability and falsifiability of the theory.\n",
            "\n",
            "Despite these challenges, string theory remains an active area of research, and many physicists continue to explore its potential to provide a unified theory of the universe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nMQyniQ-9yji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add latest AI response to messages\n",
        "messages.append(res)\n",
        "\n",
        "# now create a new user prompt\n",
        "prompt = HumanMessage(\n",
        "    content=\"Who was the 2024 Formula 1 World Champion?\"\n",
        ")\n",
        "# add to messages\n",
        "messages.append(prompt)\n",
        "\n",
        "# send to OpenAI\n",
        "res = chat(messages)"
      ],
      "metadata": {
        "id": "THu9B3pn9xrs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zjqfw_9-brQ",
        "outputId": "4b069c4f-3705-4e1a-820f-9c592746420f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't have information about future events, including the 2024 Formula 1 World Champion. My training data only goes up to 2023, and I do not have the ability to predict the future or access information that has not yet been released.\n",
            "\n",
            "However, I can suggest checking the official Formula 1 website or other reputable sources for updates on the 2024 Formula 1 season and championship standings once the season has concluded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_knowledge = (\n",
        "    \"The 2024 FIA Formula One World Championship was a motor racing championship\"\n",
        "    \"for Formula One cars and was the 75th running of the Formula One World Championship.\"\n",
        "    \"It was recognised by the Fédération Internationale de l'Automobile (FIA), the governing\"\n",
        "    \" body of international motorsport, as the highest class of competition for open-wheel\"\n",
        "    \"racing cars. The championship was contested over a record twenty-four Grands Prix held\"\n",
        "    \"around the world. Drivers and teams competed for the titles of World Drivers'\"\n",
        "    \"Champion and World Constructors' Champion, respectively. Defending Drivers'\"\n",
        "    \"Champion Max Verstappen of Red Bull Racing started off the season with seven\"\n",
        "    \"wins in the opening 10 races, but was pressured by McLaren driver Lando Norris\"\n",
        "    \" for the rest of the season after his RB20 fell behind Norris's MCL38 in\"\n",
        "    \"terms of performance. Verstappen performed consistently at the front of the\"\n",
        "    \"field and maintained his points advantage to win his fourth consecutive Drivers'\"\n",
        "    \"Championship title at the Las Vegas Grand Prix, while McLaren surpassed Red Bull\"\n",
        "    \"to achieve their ninth Constructors' Championship title at the Abu Dhabi Grand Prix,\"\n",
        "    \"narrowly ahead of Ferrari by just 14 points. With their first Constructors'\"\n",
        "    \"Championship victory in 26 years, McLaren became the first constructor other\"\n",
        "    \"than Red Bull and Mercedes to win the title since Brawn in 2009.\"\n",
        ")"
      ],
      "metadata": {
        "id": "Lvmpxman-eR1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who was the 2024 Formula 1 World Champion?\"\n",
        "\n",
        "augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
        "\n",
        "Contexts:\n",
        "{source_knowledge}\n",
        "\n",
        "Query: {query}\"\"\""
      ],
      "metadata": {
        "id": "zWrglq-X_3rX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new user prompt\n",
        "prompt = HumanMessage(\n",
        "    content=augmented_prompt\n",
        ")\n",
        "# add to messages\n",
        "messages.append(prompt)\n",
        "\n",
        "# send to OpenAI\n",
        "res = chat(messages)"
      ],
      "metadata": {
        "id": "MHXPUheN_9gZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jos_oEBZ__pZ",
        "outputId": "b492cc5f-55d9-4399-ba48-6de105912ef5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to the context, the 2024 Formula 1 World Champion (World Drivers' Champion) was Max Verstappen of Red Bull Racing, who won his fourth consecutive Drivers' Championship title at the Las Vegas Grand Prix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load CSV into Hugging Face Dataset\n",
        "dataset = load_dataset(\"csv\", data_files=\"/content/Untitled spreadsheet - Sheet1 (5).csv\", split=\"train\")\n",
        "\n",
        "print(dataset)\n",
        "print(dataset[0])  # see first row\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "ff6089a1cbc5486491bc28dfdf0842c5",
            "36c790e253404e57ab318d10f1da72dc",
            "f8c3b5e51d75412495c13bbae53eaba6",
            "a3264d5ecd9a40cea924a54894e3993b",
            "0925fcbec6f0439ea07f2f825b142b4d",
            "5c78c04788dd4e0bbc3adb836aa2b507",
            "143548f246b94f65bf5112a8a31c71bf",
            "f7cc08475e5048e3ab656ee1aa8e8440",
            "76ef52b0a5334cdd93ce494dd5284367",
            "707cc9f168e848f69c5e20beb6d5ac30",
            "a43b714ffe4e4c1a93b3736f122d7af0"
          ]
        },
        "id": "ghPqt-9KABll",
        "outputId": "e5204011-a93e-4a53-eb6f-c7f0189ca0ec"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff6089a1cbc5486491bc28dfdf0842c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['Role', 'Name', 'Specific  Role', 'Email', 'Phone', 'Office Building', 'Room', 'Website', 'Profile'],\n",
            "    num_rows: 4\n",
            "})\n",
            "{'Role': 'Associate Vice President for Research at IU', 'Name': 'Raj Acharya', 'Specific  Role': 'John H. Rudy Professor of Computing, Engineering, and Informatics at Luddy', 'Email': 'racharya@iu.edu', 'Phone': 8128563604.0, 'Office Building': ' Luddy Hall (700 N. Woodlawn Ave)', 'Room': '4032', 'Website': 'https://alliance.iu.edu/members/member/7973.html', 'Profile': \"Fellow of IEEE, ACEMB\\n\\nRaj Acharya's research interests are in the general areas of AI/ML and Data Science. He initiated the Indiana AI Collaboration Center. The center  facilitates collaboration between IU Bloomington, the Naval Surface Warfare Center Crane, the Indiana National Guard’s new Cyber Battalion, and the Indiana industry on the development of AI applications in areas that include microelectronics, cybersecurity, supply chain integrity, and fraud prevention and detection.\\n\\nAcharya has served as the Director of Academic Engagement for Joint Artificial Intelligence Center (JAIC)/Tradewind in collaboration with IN3.\\n\\nAcharya served as Dean of the Luddy School from 2016-20. He cultivated and secured a $60 Million gift from Fred Luddy to name the School as Luddy School of Informatics, Computing, and Engineering. This is the second largest private gift in Indiana University's history and includes a $22 Million gift to create the Center for Artificial Intelligence. He also oversaw the successful launch of IU's first ever engineering program. He also initiated undergraduate degrees in Data Science, and Cybersecurity & Global Policy (jointly with Hamilton Lugar School of Global and International Studies).\\n\\nPrior to his tenure at IU, he was Founding Director, School of Electrical Engineering and Computer Science (containing the Departments of Electrical Engineering and Computer Science & Engineering respectively) and Head at Penn State for 14 years. During his tenure at Penn State, research expenditure improved from 64th (2001) to 8th (2016) in the nation. The Department was awarded $48 Million US Army CRA award (Network Security), $10 Million NSF Expedition award, and $35.5 Million US Army Network Sciences Center.\\n\\nHe also held an appointment at Penn State’s Applied Research Laboratory for conducting classified research. He was previously a Research Scientist at General Electric (Thomson) CSF Laboratory, Paris, France, and has been a Research Fellow at NASA Johnson Space Center, US Air Force Wright Labs, and US Army Center for Night Vision and Electro-Optics. He is on the board of Videomining, Indiana Ventures, and Techpoint.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#knowledge base"
      ],
      "metadata": {
        "id": "msVciEM5YpNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cohere langchain-cohere\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbczDuWHjASH",
        "outputId": "83cea985-0356-43be-f904-c8f46a7cdd7a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cohere in /usr/local/lib/python3.12/dist-packages (5.18.0)\n",
            "Requirement already satisfied: langchain-cohere in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.12/dist-packages (from cohere) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.11.9)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.33.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.22.0)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.32.4.20250913)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (4.15.0)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-cohere) (0.3.21)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.76 in /usr/local/lib/python3.12/dist-packages (from langchain-cohere) (0.3.76)\n",
            "Requirement already satisfied: types-pyyaml<7.0.0.0,>=6.0.12.20240917 in /usr/local/lib/python3.12/dist-packages (from langchain-cohere) (6.0.12.20250915)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.10.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.10.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.3.45)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.76->langchain-cohere) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.76->langchain-cohere) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->cohere) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers<1,>=0.15->cohere) (0.35.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (6.6.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.12.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (1.1.10)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.76->langchain-cohere) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.3.11)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.1.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.2.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pcsk_5dnDUZ_FfhXETjsnGBVZNJP2MDho94hNZ5EmV9ptdBJN15AxUMhzEU912KsxcLUcWyHUCe"
      ],
      "metadata": {
        "id": "ZhhXHIoeYvWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "# get API key at app.pinecone.io\n",
        "api_key = os.getenv(\"PINECONE_API_KEY\") or getpass(\n",
        "    \"Enter your Pinecone API key: \"\n",
        ")\n",
        "\n",
        "# initialize client\n",
        "pc = Pinecone(api_key=api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQsZbZ36Yt-I",
        "outputId": "d66e0e3d-2322-4542-a459-d5a8110abc14"
      },
      "execution_count": 65,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Pinecone API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import ServerlessSpec, CloudProvider, AwsRegion, Metric\n",
        "\n",
        "index_name = \"luddy-rag\"\n",
        "\n",
        "# If index already exists with wrong dim, delete it first\n",
        "if pc.has_index(index_name):\n",
        "    pc.delete_index(index_name)\n",
        "\n",
        "if not pc.has_index(name=index_name):\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        metric=Metric.DOTPRODUCT,\n",
        "        dimension=1024,  # Cohere v3 embeddings are 1024\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=CloudProvider.AWS,\n",
        "            region=AwsRegion.US_EAST_1\n",
        "        )\n",
        "    )\n",
        "else:\n",
        "  print(f\"Index '{index_name}' already exists.\")\n",
        "\n",
        "index = pc.Index(name=index_name)"
      ],
      "metadata": {
        "id": "WUcQYYsqZC8w"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_cohere import CohereEmbeddings\n",
        "import os\n",
        "\n",
        "cohere_api_key = os.getenv(\"COHERE_API_KEY\") or getpass(\n",
        "    \"Enter your COHERE API key: \"\n",
        ")\n",
        "\n",
        "embed_model = CohereEmbeddings(model=\"embed-english-v3.0\", cohere_api_key=cohere_api_key)\n",
        "#PqUDbnd7832givEjvgjTDaSUGSb9B22TKecnE8xE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHcqEU_ZjIhd",
        "outputId": "fa4f71c9-b59d-4555-e221-18088eb634f7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your COHERE API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    'this is the first chunk of text',\n",
        "    'then another second chunk of text is here'\n",
        "]\n",
        "\n",
        "res = embed_model.embed_documents(texts)\n",
        "len(res), len(res[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNltd0tCkjSY",
        "outputId": "97d3f3b6-fb60-4601-a525-c14b5a8b5869"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "data = dataset.to_pandas()\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "def clean_value(v):\n",
        "    if pd.isna(v):   # replace NaN/None\n",
        "        return \"\"\n",
        "    return str(v)    # ensure string type for JSON compatibility\n",
        "\n",
        "for i in tqdm(range(0, len(data), batch_size)):\n",
        "    i_end = min(len(data), i+batch_size)\n",
        "    batch = data.iloc[i:i_end]\n",
        "\n",
        "    # unique ids\n",
        "    ids = [f\"{x['Name']}_{i}\" for i, x in batch.iterrows()]\n",
        "\n",
        "    # text to embed\n",
        "    texts = [clean_value(x['Profile']) for _, x in batch.iterrows()]\n",
        "\n",
        "    # embeddings\n",
        "    embeds = embed_model.embed_documents(texts)\n",
        "\n",
        "    # metadata\n",
        "    metadata = [\n",
        "        {\n",
        "            'text': clean_value(x['Profile']),\n",
        "            'name': clean_value(x['Name']),\n",
        "            'role': clean_value(x['Role']),\n",
        "            'specific_role': clean_value(x['Specific  Role']),\n",
        "            'email': clean_value(x['Email']),\n",
        "            'phone': clean_value(x['Phone']),\n",
        "            'office_building': clean_value(x['Office Building']),\n",
        "            'room': clean_value(x['Room']),\n",
        "            'website': clean_value(x['Website'])\n",
        "        }\n",
        "        for _, x in batch.iterrows()\n",
        "    ]\n",
        "\n",
        "    # upsert\n",
        "    index.upsert(vectors=zip(ids, embeds, metadata))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "114ff34dc0574fa4b68cec2720c174b8",
            "f70ead906c0d449d88fb32134dce4878",
            "a85ef2bef2e54899bc3a52f560674d30",
            "c03ce78d31e94034b2f849a12ecf7128",
            "3e41c26223124bbea716420dc894faa7",
            "257833c710a84ffc9842ef45c8970ffa",
            "104ad1ea624849d2b906c34ee19edb72",
            "9e6f26203bcb4d03ad13772550bfc171",
            "1ad5c23abcb8469c95e1c927ac63bce7",
            "c06055521f1b42b39ca64d2a7f92536e",
            "e86e0ae28cc64c4d812bd8b541490ecf"
          ]
        },
        "id": "3ho2WFhZvrjY",
        "outputId": "a46d4264-ef75-4e54-e938-bd45a80bf882"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "114ff34dc0574fa4b68cec2720c174b8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-WHSlD1nKXM",
        "outputId": "159c9588-62a7-4705-80a9-13c755241ff6"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1024,\n",
              " 'index_fullness': 0.0,\n",
              " 'metric': 'dotproduct',\n",
              " 'namespaces': {'': {'vector_count': 4}},\n",
              " 'total_vector_count': 4,\n",
              " 'vector_type': 'dense'}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HZ6bAMYYam3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "text_field = \"text\"  # the metadata field that contains our text\n",
        "\n",
        "# initialize the vector store object\n",
        "vectorstore = PineconeVectorStore(\n",
        "    index=index,\n",
        "    embedding=embed_model,\n",
        "    text_key=text_field\n",
        ")"
      ],
      "metadata": {
        "id": "zvUO0_43nWyx"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is so special about Raj Acharya?\"\n",
        "\n",
        "vectorstore.similarity_search(query, k=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urGiW-6nnaOk",
        "outputId": "3a5fb24a-bdf0-4360-9853-d87436b328a3"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='Mary Jean Amon_3', metadata={'email': 'mjamon@iu.edu', 'name': 'Mary Jean Amon', 'office_building': 'Myles Brand Hall', 'phone': '', 'role': 'Assistant Professor', 'room': 'E302', 'specific_role': '', 'website': ''}, page_content=\"Dr. Mary Jean Amon is an Assistant Professor in Indiana University Bloomington's Department of Informatics. Before joining UCF, she was a Postdoctoral Researcher in the Department of Psychological and Brain Sciences at Indiana University Bloomington, a Research Associate in the Institute of Cognitive Science at the University of Colorado Boulder, and then an Assistant Professor in the School of Modeling, Simulation, and Training at the University of Central Florida. Her interdisciplinary research is informed by topics in cognitive science, computer science, and data science and centers on user-oriented research aimed toward optimizing decision-making and performance in the context of complex socio-technological systems. This includes augmenting our understanding of teamwork by identifying coordinative patterns and features of socio-technical tasks that enhance performance, as well as how the dynamics of human-computer interaction inform issues associated with online privacy.\"),\n",
              " Document(id='Shamim R. Ali_2', metadata={'email': 'srazawi@iu.edu', 'name': 'Shamim R. Ali', 'office_building': 'Luddy Hall (700 N. Woodlawn Ave)', 'phone': '', 'role': 'Associate Director of Undergraduate Advising', 'room': '1022', 'specific_role': \"Academic Advisor - Master's\", 'website': ''}, page_content='M.S. in Applied Health Science at Indiana University, Bloomington, 2010 B.S. in Health Science at California State University, East Bay, 1994'),\n",
              " Document(id='Raj Acharya_0', metadata={'email': 'racharya@iu.edu', 'name': 'Raj Acharya', 'office_building': ' Luddy Hall (700 N. Woodlawn Ave)', 'phone': '8128563604.0', 'role': 'Associate Vice President for Research at IU', 'room': '4032', 'specific_role': 'John H. Rudy Professor of Computing, Engineering, and Informatics at Luddy', 'website': 'https://alliance.iu.edu/members/member/7973.html'}, page_content=\"Fellow of IEEE, ACEMB\\n\\nRaj Acharya's research interests are in the general areas of AI/ML and Data Science. He initiated the Indiana AI Collaboration Center. The center  facilitates collaboration between IU Bloomington, the Naval Surface Warfare Center Crane, the Indiana National Guard’s new Cyber Battalion, and the Indiana industry on the development of AI applications in areas that include microelectronics, cybersecurity, supply chain integrity, and fraud prevention and detection.\\n\\nAcharya has served as the Director of Academic Engagement for Joint Artificial Intelligence Center (JAIC)/Tradewind in collaboration with IN3.\\n\\nAcharya served as Dean of the Luddy School from 2016-20. He cultivated and secured a $60 Million gift from Fred Luddy to name the School as Luddy School of Informatics, Computing, and Engineering. This is the second largest private gift in Indiana University's history and includes a $22 Million gift to create the Center for Artificial Intelligence. He also oversaw the successful launch of IU's first ever engineering program. He also initiated undergraduate degrees in Data Science, and Cybersecurity & Global Policy (jointly with Hamilton Lugar School of Global and International Studies).\\n\\nPrior to his tenure at IU, he was Founding Director, School of Electrical Engineering and Computer Science (containing the Departments of Electrical Engineering and Computer Science & Engineering respectively) and Head at Penn State for 14 years. During his tenure at Penn State, research expenditure improved from 64th (2001) to 8th (2016) in the nation. The Department was awarded $48 Million US Army CRA award (Network Security), $10 Million NSF Expedition award, and $35.5 Million US Army Network Sciences Center.\\n\\nHe also held an appointment at Penn State’s Applied Research Laboratory for conducting classified research. He was previously a Research Scientist at General Electric (Thomson) CSF Laboratory, Paris, France, and has been a Research Fellow at NASA Johnson Space Center, US Air Force Wright Labs, and US Army Center for Night Vision and Electro-Optics. He is on the board of Videomining, Indiana Ventures, and Techpoint.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_prompt(query: str):\n",
        "    # get top 3 results from knowledge base\n",
        "    results = vectorstore.similarity_search(query, k=3)\n",
        "    # get the text from the results\n",
        "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
        "    # feed into an augmented prompt\n",
        "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
        "\n",
        "    Contexts:\n",
        "    {source_knowledge}\n",
        "\n",
        "    Query: {query}\"\"\"\n",
        "    return augmented_prompt"
      ],
      "metadata": {
        "id": "E5pJIwCzncrz"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(augment_prompt(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmQ7wAx6qk2n",
        "outputId": "8cbf89d8-dbd1-455c-ba31-d4ed7c241c4e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the contexts below, answer the query.\n",
            "\n",
            "    Contexts:\n",
            "    Dr. Mary Jean Amon is an Assistant Professor in Indiana University Bloomington's Department of Informatics. Before joining UCF, she was a Postdoctoral Researcher in the Department of Psychological and Brain Sciences at Indiana University Bloomington, a Research Associate in the Institute of Cognitive Science at the University of Colorado Boulder, and then an Assistant Professor in the School of Modeling, Simulation, and Training at the University of Central Florida. Her interdisciplinary research is informed by topics in cognitive science, computer science, and data science and centers on user-oriented research aimed toward optimizing decision-making and performance in the context of complex socio-technological systems. This includes augmenting our understanding of teamwork by identifying coordinative patterns and features of socio-technical tasks that enhance performance, as well as how the dynamics of human-computer interaction inform issues associated with online privacy.\n",
            "M.S. in Applied Health Science at Indiana University, Bloomington, 2010 B.S. in Health Science at California State University, East Bay, 1994\n",
            "Fellow of IEEE, ACEMB\n",
            "\n",
            "Raj Acharya's research interests are in the general areas of AI/ML and Data Science. He initiated the Indiana AI Collaboration Center. The center  facilitates collaboration between IU Bloomington, the Naval Surface Warfare Center Crane, the Indiana National Guard’s new Cyber Battalion, and the Indiana industry on the development of AI applications in areas that include microelectronics, cybersecurity, supply chain integrity, and fraud prevention and detection.\n",
            "\n",
            "Acharya has served as the Director of Academic Engagement for Joint Artificial Intelligence Center (JAIC)/Tradewind in collaboration with IN3.\n",
            "\n",
            "Acharya served as Dean of the Luddy School from 2016-20. He cultivated and secured a $60 Million gift from Fred Luddy to name the School as Luddy School of Informatics, Computing, and Engineering. This is the second largest private gift in Indiana University's history and includes a $22 Million gift to create the Center for Artificial Intelligence. He also oversaw the successful launch of IU's first ever engineering program. He also initiated undergraduate degrees in Data Science, and Cybersecurity & Global Policy (jointly with Hamilton Lugar School of Global and International Studies).\n",
            "\n",
            "Prior to his tenure at IU, he was Founding Director, School of Electrical Engineering and Computer Science (containing the Departments of Electrical Engineering and Computer Science & Engineering respectively) and Head at Penn State for 14 years. During his tenure at Penn State, research expenditure improved from 64th (2001) to 8th (2016) in the nation. The Department was awarded $48 Million US Army CRA award (Network Security), $10 Million NSF Expedition award, and $35.5 Million US Army Network Sciences Center.\n",
            "\n",
            "He also held an appointment at Penn State’s Applied Research Laboratory for conducting classified research. He was previously a Research Scientist at General Electric (Thomson) CSF Laboratory, Paris, France, and has been a Research Fellow at NASA Johnson Space Center, US Air Force Wright Labs, and US Army Center for Night Vision and Electro-Optics. He is on the board of Videomining, Indiana Ventures, and Techpoint.\n",
            "\n",
            "    Query: What is so special about Raj Acharya?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new user prompt\n",
        "prompt = HumanMessage(\n",
        "    content=augment_prompt(query)\n",
        ")\n",
        "# add to messages\n",
        "messages.append(prompt)\n",
        "\n",
        "res = chat(messages)\n",
        "\n",
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g76UJjOXqnFC",
        "outputId": "6033c7b1-99a1-4572-aeb4-3e71c3420701"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raj Acharya is special because of his numerous achievements and contributions to the field of AI, ML, and Data Science. Some of his notable accomplishments include:\n",
            "\n",
            "1. **Initiating the Indiana AI Collaboration Center**: He brought together IU Bloomington, the Naval Surface Warfare Center Crane, the Indiana National Guard, and the Indiana industry to develop AI applications in areas like microelectronics, cybersecurity, and supply chain integrity.\n",
            "2. **Securing a $60 Million gift**: He secured a significant private gift from Fred Luddy to name the Luddy School of Informatics, Computing, and Engineering, which is the second-largest private gift in Indiana University's history.\n",
            "3. **Launching IU's first engineering program**: He oversaw the successful launch of IU's first-ever engineering program, which is a significant milestone for the university.\n",
            "4. **Improving research expenditure**: During his tenure at Penn State, he improved the research expenditure from 64th to 8th in the nation, which is a remarkable achievement.\n",
            "5. **Receiving significant awards**: He received notable awards, including a $48 Million US Army CRA award, a $10 Million NSF Expedition award, and a $35.5 Million US Army Network Sciences Center award.\n",
            "6. **Holding prestigious appointments**: He held appointments at Penn State's Applied Research Laboratory, General Electric (Thomson) CSF Laboratory, NASA Johnson Space Center, US Air Force Wright Labs, and US Army Center for Night Vision and Electro-Optics.\n",
            "7. **Being a Fellow of IEEE and ACEMB**: He is a Fellow of the Institute of Electrical and Electronics Engineers (IEEE) and the American College of Epidemiology and Medical Informatics (ACEMB), which is a recognition of his expertise and contributions to the field.\n",
            "\n",
            "Overall, Raj Acharya is a highly accomplished individual with a strong track record of achievements in AI, ML, and Data Science, and his contributions have had a significant impact on the field and the institutions he has been associated with.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = HumanMessage(\n",
        "    content=augment_prompt(\n",
        "        \"anyone studied in italy\"\n",
        "    )\n",
        ")\n",
        "\n",
        "res = chat(messages + [prompt])\n",
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R6--bSdq5q9",
        "outputId": "cac8ce2d-edbb-4a3c-e937-934e8cdda3ce"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, someone has studied in Italy. According to the context, a person (whose name is not mentioned) has completed their:\n",
            "\n",
            "* Ph.D. in Electronics and Communication Engineering at Politecnico di Torino, Italy, 2014\n",
            "* M.S. in Telecommunication Engineering at Politecnico di Torino, Italy, 2010\n",
            "\n",
            "So, this person has studied in Italy, specifically at the Politecnico di Torino.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = HumanMessage(\n",
        "    content=augment_prompt(\n",
        "        \"where did Akhlaque Ahmed study?\"\n",
        "    )\n",
        ")\n",
        "\n",
        "res = chat(messages + [prompt])\n",
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo6tVZR6wlLP",
        "outputId": "40babfa6-4ef1-43ce-af6a-6183b42d1759"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is no information about Akhlaque Ahmed in the provided contexts. The contexts mention Dr. Mary Jean Amon, Raj Acharya, and their educational backgrounds and research interests, but they do not mention Akhlaque Ahmed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "id": "gVAADm-W0vWQ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BqFw69RG5y87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "# --- Streamlit UI ---\n",
        "st.set_page_config(page_title=\"RAG Chatbot\", layout=\"centered\")\n",
        "st.title(\"🤖 Faculty RAG Chatbot\")\n",
        "st.write(\"Ask a question about the faculty dataset.\")\n",
        "\n",
        "# chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# input box\n",
        "query = st.text_input(\"You:\", \"\")\n",
        "\n",
        "if query:\n",
        "    # 1. Retrieve relevant context from Pinecone\n",
        "    docs = vectorstore.similarity_search(query, k=3)\n",
        "\n",
        "    context_text = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "    # 2. Create prompt with context\n",
        "    prompt_text = f\"Answer the question using the context below. If the answer is not in the context, say so.\\n\\nContext:\\n{context_text}\\n\\nQuestion: {query}\"\n",
        "\n",
        "    prompt = HumanMessage(content=prompt_text)\n",
        "\n",
        "    # 3. Get response from chat model\n",
        "    res = chat([*st.session_state.messages, prompt])\n",
        "\n",
        "    # 4. Update chat history\n",
        "    st.session_state.messages.append(HumanMessage(content=query))\n",
        "    st.session_state.messages.append(res)\n",
        "\n",
        "    # 5. Display\n",
        "    st.markdown(f\"**Answer:** {res.content}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrdvWxBL015N",
        "outputId": "61bd7fea-5f43-4248-c780-33ac31a7738d"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "# --- Streamlit UI ---\n",
        "st.set_page_config(page_title=\"RAG Chatbot\", layout=\"centered\")\n",
        "st.title(\"🤖 Faculty RAG Chatbot\")\n",
        "st.write(\"Ask a question about the faculty dataset.\")\n",
        "\n",
        "# --- Chat history ---\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# --- Input box inside a form (fixes typing issue) ---\n",
        "with st.form(key=\"chat_form\", clear_on_submit=True):\n",
        "    query = st.text_input(\"You:\")\n",
        "    submit_button = st.form_submit_button(\"Send\")\n",
        "\n",
        "if submit_button and query:\n",
        "    # 1. Retrieve relevant context from Pinecone\n",
        "    docs = vectorstore.similarity_search(query, k=3)\n",
        "    context_text = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "    # 2. Create prompt with context\n",
        "    prompt_text = f\"Answer the question using the context below. If the answer is not in the context, say so.\\n\\nContext:\\n{context_text}\\n\\nQuestion: {query}\"\n",
        "    prompt = HumanMessage(content=prompt_text)\n",
        "\n",
        "    # 3. Get response from chat model\n",
        "    res = chat([*st.session_state.messages, prompt])\n",
        "\n",
        "    # 4. Update chat history\n",
        "    st.session_state.messages.append(HumanMessage(content=query))\n",
        "    st.session_state.messages.append(res)\n",
        "\n",
        "# --- Display chat history ---\n",
        "for i in range(0, len(st.session_state.messages), 2):\n",
        "    user_msg = st.session_state.messages[i].content\n",
        "    bot_msg = st.session_state.messages[i+1].content\n",
        "    st.markdown(f\"**You:** {user_msg}\")\n",
        "    st.markdown(f\"**Bot:** {bot_msg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u_gLrxT6Q4E",
        "outputId": "538e2c34-19ae-413c-828e-f7e96fc21173"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euMAWpLW05YU",
        "outputId": "9336734c-69bf-4c86-dd85-3239fd9aaf86"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "up to date, audited 23 packages in 844ms\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "yQOzj8Zm0_pX"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAvttyM_1EGj",
        "outputId": "70acd469-7de1-4ce9-c138-7202bfa10d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.245.161.33\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0Kyour url is: https://empty-rooms-repair.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fq-VnTn_x6aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc.delete_index(index_name)"
      ],
      "metadata": {
        "id": "M0jclvYKrDRK"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UUd-Z2b-rF3j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}